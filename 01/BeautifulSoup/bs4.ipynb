{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.crummy.com/software/BeautifulSoup/bs4/doc/index.zh.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 快速开始"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 下面的一段HTML代码将作为例子被多次用到.这是 爱丽丝梦游仙境的 的一段内容(以后内容中简称为 爱丽丝 的文档):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ruff: ignore\n",
    "html_doc = r\"\"\"\n",
    "<html><head><title>The Dormouse's story</title></head>\n",
    "<body>\n",
    "<p class=\"title\"><b>The Dormouse's story</b></p>\n",
    "\n",
    "<p class=\"story\">Once upon a time there were three little sisters; and their names were\n",
    "<a href=\"http://example.com/elsie\" class=\"sister\" id=\"link1\">Elsie</a>,\n",
    "<a href=\"http://example.com/lacie\" class=\"sister\" id=\"link2\">Lacie</a> and\n",
    "<a href=\"http://example.com/tillie\" class=\"sister\" id=\"link3\">Tillie</a>;\n",
    "and they lived at the bottom of a well.</p>\n",
    "\n",
    "<p class=\"story\">...</p>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用BeautifulSoup解析这段代码,能够得到一个 BeautifulSoup 的对象,并能按照标准的缩进格式的结构输出:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<html><head><title>The Dormouse's story</title></head>\n",
       "<body>\n",
       "<p class=\"title\"><b>The Dormouse's story</b></p>\n",
       "<p class=\"story\">Once upon a time there were three little sisters; and their names were\n",
       "<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>,\n",
       "<a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a> and\n",
       "<a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>;\n",
       "and they lived at the bottom of a well.</p>\n",
       "<p class=\"story\">...</p>\n",
       "</body></html>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup = BeautifulSoup(html_doc)\n",
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html>\n",
      " <head>\n",
      "  <title>\n",
      "   The Dormouse's story\n",
      "  </title>\n",
      " </head>\n",
      " <body>\n",
      "  <p class=\"title\">\n",
      "   <b>\n",
      "    The Dormouse's story\n",
      "   </b>\n",
      "  </p>\n",
      "  <p class=\"story\">\n",
      "   Once upon a time there were three little sisters; and their names were\n",
      "   <a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">\n",
      "    Elsie\n",
      "   </a>\n",
      "   ,\n",
      "   <a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">\n",
      "    Lacie\n",
      "   </a>\n",
      "   and\n",
      "   <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">\n",
      "    Tillie\n",
      "   </a>\n",
      "   ;\n",
      "and they lived at the bottom of a well.\n",
      "  </p>\n",
      "  <p class=\"story\">\n",
      "   ...\n",
      "  </p>\n",
      " </body>\n",
      "</html>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 几个简单的浏览结构化数据的方法:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<title>The Dormouse's story</title>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'title'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.title.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The Dormouse's story\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.title.string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'head'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.title.parent.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<p class=\"title\"><b>The Dormouse's story</b></p>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['title']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.p['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>,\n",
       " <a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>,\n",
       " <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find(id='link3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 从文档中找到所有 \\<a> 标签的链接:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://example.com/elsie\n",
      "http://example.com/lacie\n",
      "http://example.com/tillie\n"
     ]
    }
   ],
   "source": [
    "for link in soup.find_all('a'):\n",
    "    print(link.get('href'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 从文档中获取所有文字内容:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Dormouse's story\n",
      "\n",
      "The Dormouse's story\n",
      "Once upon a time there were three little sisters; and their names were\n",
      "Elsie,\n",
      "Lacie and\n",
      "Tillie;\n",
      "and they lived at the bottom of a well.\n",
      "...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(soup.get_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 如何使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<html><body><p>data</p></body></html>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# soup = BeautifulSoup(open(\"index.html\"))\n",
    "soup = BeautifulSoup('<html>data</html>')\n",
    "soup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 对象的种类"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tag\n",
    "\n",
    "Tag 对象与XML或HTML原生文档中的tag相同:\n",
    "\n",
    "Tag有很多方法和属性,在 遍历文档树 和 搜索文档树 中有详细解释.现在介绍一下tag中最重要的属性: name和attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<html><body><b class=\"boldest\">Extremely bold</b></body></html>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup = BeautifulSoup('<b class=\"boldest\">Extremely bold</b>')\n",
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<b class=\"boldest\">Extremely bold</b>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag = soup.b\n",
    "tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bs4.element.Tag"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Name\n",
    "\n",
    "每个tag都有自己的名字,通过 .name 来获取:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'b'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<blockquote class=\"boldest\">Extremely bold</blockquote>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 如果改变了tag的name,那将影响所有通过当前Beautiful Soup对象生成的HTML文档:\n",
    "tag.name = 'blockquote'\n",
    "tag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attributes\n",
    "\n",
    "一个tag可能有很多个属性. tag \\<b class=\"boldest\"> 有一个 “class” 的属性,值为 “boldest” . tag的属性的操作方法与字典相同:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['boldest']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'class': ['boldest']}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 也可以直接”点”取属性, 比如: .attrs :\n",
    "tag.attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<blockquote class=\"verybold\" id=\"1\">Extremely bold</blockquote>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tag的属性可以被添加,删除或修改. 再说一次, tag的属性操作方法与字典一样\n",
    "tag['class'] = 'verybold'\n",
    "tag['id'] = 1\n",
    "tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<blockquote>Extremely bold</blockquote>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del tag['class']\n",
    "del tag['id']\n",
    "tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'class'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Administrator\\Desktop\\self\\PythonLearn\\01\\BeautifulSoup\\bs4.ipynb 单元格 38\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Administrator/Desktop/self/PythonLearn/01/BeautifulSoup/bs4.ipynb#X52sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m tag[\u001b[39m'\u001b[39;49m\u001b[39mclass\u001b[39;49m\u001b[39m'\u001b[39;49m]\n",
      "File \u001b[1;32md:\\miniconda3\\envs\\pytorch\\Lib\\site-packages\\bs4\\element.py:1573\u001b[0m, in \u001b[0;36mTag.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1570\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, key):\n\u001b[0;32m   1571\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"tag[key] returns the value of the 'key' attribute for the Tag,\u001b[39;00m\n\u001b[0;32m   1572\u001b[0m \u001b[39m    and throws an exception if it's not there.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1573\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mattrs[key]\n",
      "\u001b[1;31mKeyError\u001b[0m: 'class'"
     ]
    }
   ],
   "source": [
    "tag['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(tag.get('class'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 多值属性\n",
    "\n",
    "HTML 4定义了一系列可以包含多个值的属性.在HTML5中移除了一些,却增加更多.最常见的多值的属性是 class (一个tag可以有多个CSS的class). 还有一些属性 rel , rev , accept-charset , headers , accesskey . 在Beautiful Soup中多值属性的返回类型是list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['body', 'strikeout']"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "css_soup = BeautifulSoup('<p class=\"body strikeout\"></p>')\n",
    "css_soup.p['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['body']"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "css_soup = BeautifulSoup('<p class=\"body\"></p>')\n",
    "css_soup.p['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'my id'"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 如果某个属性看起来好像有多个值,但在任何版本的HTML定义中都没有被定义为多值属性,那么Beautiful Soup会将这个属性作为字符串返回\n",
    "id_soup = BeautifulSoup('<p id=\"my id\"></p>')\n",
    "id_soup.p['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['index']"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 将tag转换成字符串时,多值属性会合并为一个值\n",
    "rel_soup = BeautifulSoup('<p>Back to the <a rel=\"index\">homepage</a></p>')\n",
    "rel_soup.a['rel']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['index', 'contents']"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rel_soup.a['rel'] = ['index', 'contents']\n",
    "rel_soup.a['rel']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'body strikeout'"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 如果转换的文档是XML格式,那么tag中不包含多值属性\n",
    "xml_soup = BeautifulSoup('<p class=\"body strikeout\"></p>', 'xml')\n",
    "xml_soup.p['class']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 可以遍历的字符串\n",
    "\n",
    "字符串常被包含在tag内.Beautiful Soup用 NavigableString 类来包装tag中的字符串:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<blockquote>Extremely bold</blockquote>"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Extremely bold'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag.string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bs4.element.NavigableString"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tag.string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Extremely bold'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 一个 NavigableString 字符串与Python中的Unicode字符串相同,并且还支持包含在 遍历文档树 和 搜索文档树 中的一些特性.\n",
    "# 通过 unicode() 方法可以直接将 NavigableString 对象转换成Unicode字符串:\n",
    "# python3中str()代替了unicode()\n",
    "unicode_string = str(tag.string)\n",
    "unicode_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(unicode_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<blockquote>No longer bold</blockquote>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tag中包含的字符串不能编辑,但是可以被替换成其它的字符串,用 replace_with() 方法:\n",
    "tag.string.replace_with(\"No longer bold\")\n",
    "tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NavigableString 对象支持 遍历文档树 和 搜索文档树 中定义的大部分属性, 并非全部.\n",
    "# 尤其是,一个字符串不能包含其它内容(tag能够包含字符串或是其它tag),字符串不支持 .contents 或 .string 属性或 find() 方法.\n",
    "# 如果想在Beautiful Soup之外使用 NavigableString 对象,需要调用 unicode() 方法,将该对象转换成普通的Unicode字符串,\n",
    "# 否则就算Beautiful Soup已方法已经执行结束,该对象的输出也会带有对象的引用地址.这样会浪费内存."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BeautifulSoup\n",
    "\n",
    "BeautifulSoup 对象表示的是一个文档的全部内容.大部分时候,可以把它当作 Tag 对象,它支持 遍历文档树 和 搜索文档树 中描述的大部分的方法.\n",
    "\n",
    "因为 BeautifulSoup 对象并不是真正的HTML或XML的tag,所以它没有name和attribute属性.但有时查看它的 .name 属性是很方便的,所以 BeautifulSoup 对象包含了一个值为 “[document]” 的特殊属性 .name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[document]'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 注释及特殊字符串\n",
    "\n",
    "Tag , NavigableString , BeautifulSoup 几乎覆盖了html和xml中的所有内容,但是还有一些特殊对象.容易让人担心的内容是文档的注释部分:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bs4.element.Comment"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "markup = \"<b><!--Hey, buddy. Want to buy a used parser?--></b>\"\n",
    "soup = BeautifulSoup(markup)\n",
    "comment = soup.b.string\n",
    "type(comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hey, buddy. Want to buy a used parser?'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Comment 对象是一个特殊类型的 NavigableString 对象:\n",
    "comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<b>\n",
      " <!--Hey, buddy. Want to buy a used parser?-->\n",
      "</b>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 但是当它出现在HTML文档中时, Comment 对象会使用特殊的格式输出:\n",
    "print(soup.b.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<b>\n",
      " <![CDATA[A CDATA block]]>\n",
      "</b>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Beautiful Soup中定义的其它类型都可能会出现在XML的文档中: CData , ProcessingInstruction , Declaration , Doctype .\n",
    "# 与 Comment 对象类似,这些类都是 NavigableString 的子类,只是添加了一些额外的方法的字符串独享.下面是用CDATA来替代注释的例子:\n",
    "from bs4 import CData\n",
    "cdata = CData(\"A CDATA block\")\n",
    "comment.replace_with(cdata)\n",
    "print(soup.b.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 遍历文档树"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<html><head><title>The Dormouse's story</title></head>\n",
       "<body><p class=\"title\"><b>The Dormouse's story</b></p>\n",
       "<p class=\"story\">Once upon a time there were three little sisters; and their names were\n",
       "<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>,\n",
       "<a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a> and\n",
       "<a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>;\n",
       "and they lived at the bottom of a well.</p>\n",
       "<p class=\"story\">...</p>\n",
       "</body></html>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 还拿”爱丽丝梦游仙境”的文档来做例子:\n",
    "# 通过这段例子来演示怎样从文档的一段内容找到另一段内容\n",
    "html_doc = \"\"\"\n",
    "<html><head><title>The Dormouse's story</title></head>\n",
    "\n",
    "<p class=\"title\"><b>The Dormouse's story</b></p>\n",
    "\n",
    "<p class=\"story\">Once upon a time there were three little sisters; and their names were\n",
    "<a href=\"http://example.com/elsie\" class=\"sister\" id=\"link1\">Elsie</a>,\n",
    "<a href=\"http://example.com/lacie\" class=\"sister\" id=\"link2\">Lacie</a> and\n",
    "<a href=\"http://example.com/tillie\" class=\"sister\" id=\"link3\">Tillie</a>;\n",
    "and they lived at the bottom of a well.</p>\n",
    "\n",
    "<p class=\"story\">...</p>\n",
    "\"\"\"\n",
    "soup = BeautifulSoup(html_doc)\n",
    "soup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 子节点\n",
    "\n",
    "一个Tag可能包含多个字符串或其它的Tag,这些都是这个Tag的子节点.Beautiful Soup提供了许多操作和遍历子节点的属性.\n",
    "\n",
    "注意: Beautiful Soup中字符串节点不支持这些属性,因为字符串没有子节点"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tag的名字\n",
    "\n",
    "操作文档树最简单的方法就是告诉它你想获取的tag的name.如果想获取 <head> 标签,只要用 soup.head :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<head><title>The Dormouse's story</title></head>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<title>The Dormouse's story</title>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<b>The Dormouse's story</b>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 这是个获取tag的小窍门,可以在文档树的tag中多次调用这个方法.下面的代码可以获取<body>标签中的第一个<b>标签:\n",
    "soup.body.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 通过点取属性的方式只能获得当前名字的第一个tag:\n",
    "soup.a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 通过点取属性的方式只能获得当前名字的第一个tag:\n",
    "soup.body.a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>,\n",
       " <a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>,\n",
       " <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 如果想要得到所有的<a>标签,或是通过名字得到比一个tag更多的内容的时候,就需要用到 Searching the tree 中描述的方法,比如: find_all()\n",
    "soup.find_all('a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### .contents 和 .children\n",
    "\n",
    "tag的 .contents 属性可以将tag的子节点以列表的方式输出:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<head><title>The Dormouse's story</title></head>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "head_tag = soup.head\n",
    "head_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<title>The Dormouse's story</title>]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "head_tag.contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<title>The Dormouse's story</title>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_tag = head_tag.contents[0]\n",
    "title_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"The Dormouse's story\"]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_tag.contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BeautifulSoup 对象本身一定会包含子节点,也就是说<html>标签也是 BeautifulSoup 对象的子节点:\n",
    "len(soup.contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'html'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.contents[0].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NavigableString' object has no attribute 'contents'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Administrator\\Desktop\\self\\PythonLearn\\01\\BeautifulSoup\\bs4.ipynb 单元格 79\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Administrator/Desktop/self/PythonLearn/01/BeautifulSoup/bs4.ipynb#Y141sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# 字符串没有 .contents 属性,因为字符串没有子节点:\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Administrator/Desktop/self/PythonLearn/01/BeautifulSoup/bs4.ipynb#Y141sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m text \u001b[39m=\u001b[39m title_tag\u001b[39m.\u001b[39mcontents[\u001b[39m0\u001b[39m]\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Administrator/Desktop/self/PythonLearn/01/BeautifulSoup/bs4.ipynb#Y141sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m text\u001b[39m.\u001b[39;49mcontents\n",
      "File \u001b[1;32md:\\miniconda3\\envs\\pytorch\\Lib\\site-packages\\bs4\\element.py:984\u001b[0m, in \u001b[0;36mNavigableString.__getattr__\u001b[1;34m(self, attr)\u001b[0m\n\u001b[0;32m    982\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n\u001b[0;32m    983\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 984\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\n\u001b[0;32m    985\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m object has no attribute \u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (\n\u001b[0;32m    986\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, attr))\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NavigableString' object has no attribute 'contents'"
     ]
    }
   ],
   "source": [
    "# 字符串没有 .contents 属性,因为字符串没有子节点:\n",
    "text = title_tag.contents[0]\n",
    "text.contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Dormouse's story\n"
     ]
    }
   ],
   "source": [
    "for child in title_tag.children:\n",
    "    print(child)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### .descendants\n",
    "\n",
    ".contents 和 .children 属性仅包含tag的直接子节点.例如,\\<head>标签只有一个直接子节点\\<title>\n",
    "\n",
    "但是\\<title>标签也包含一个子节点:字符串 “The Dormouse’s story”,这种情况下字符串“The Dormouse’s story”也属于\\<head>标签的子孙节点.\n",
    "\n",
    ".descendants 属性可以对所有tag的子孙节点进行递归循环:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<title>The Dormouse's story</title>]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "head_tag.contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<title>The Dormouse's story</title>\n",
      "The Dormouse's story\n"
     ]
    }
   ],
   "source": [
    "for child in head_tag.descendants:\n",
    "    print(child)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 上面的例子中, <head>标签只有一个子节点,但是有2个子孙节点:<head>节点和<head>的子节点,\n",
    "# BeautifulSoup 有一个直接子节点(<html>节点),却有很多子孙节点:\n",
    "len(list(soup.children))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(soup.descendants))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### .string\n",
    "\n",
    "如果tag只有一个 NavigableString 类型子节点,那么这个tag可以使用 .string 得到子节点:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<title>The Dormouse's story</title>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The Dormouse's story\""
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_tag.string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<title>The Dormouse's story</title>]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 如果一个tag仅有一个子节点,那么这个tag也可以使用 .string 方法,输出结果与当前唯一子节点的 .string 结果相同:\n",
    "head_tag.contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The Dormouse's story\""
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "head_tag.string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "# 如果tag包含了多个子节点,tag就无法确定 .string 方法应该调用哪个子节点的内容, .string 的输出结果是 None :\n",
    "print(soup.html.string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### .strings 和 stripped_strings\n",
    "\n",
    "如果tag中包含多个字符串 [2] ,可以使用 .strings 来循环获取:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"The Dormouse's story\",\n",
       " '\\n',\n",
       " \"The Dormouse's story\",\n",
       " '\\n',\n",
       " 'Once upon a time there were three little sisters; and their names were\\n',\n",
       " 'Elsie',\n",
       " ',\\n',\n",
       " 'Lacie',\n",
       " ' and\\n',\n",
       " 'Tillie',\n",
       " ';\\nand they lived at the bottom of a well.',\n",
       " '\\n',\n",
       " '...',\n",
       " '\\n']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(soup.strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"The Dormouse's story\"\n",
      "'\\n'\n",
      "\"The Dormouse's story\"\n",
      "'\\n'\n",
      "'Once upon a time there were three little sisters; and their names were\\n'\n",
      "'Elsie'\n",
      "',\\n'\n",
      "'Lacie'\n",
      "' and\\n'\n",
      "'Tillie'\n",
      "';\\nand they lived at the bottom of a well.'\n",
      "'\\n'\n",
      "'...'\n",
      "'\\n'\n"
     ]
    }
   ],
   "source": [
    "for string in soup.strings:\n",
    "    print(repr(string)) # repr 正确打印出 `\\n`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"The Dormouse's story\",\n",
       " \"The Dormouse's story\",\n",
       " 'Once upon a time there were three little sisters; and their names were',\n",
       " 'Elsie',\n",
       " ',',\n",
       " 'Lacie',\n",
       " 'and',\n",
       " 'Tillie',\n",
       " ';\\nand they lived at the bottom of a well.',\n",
       " '...']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 输出的字符串中可能包含了很多空格或空行,使用 .stripped_strings 可以去除多余空白内容:\n",
    "list(soup.stripped_strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"The Dormouse's story\"\n",
      "\"The Dormouse's story\"\n",
      "'Once upon a time there were three little sisters; and their names were'\n",
      "'Elsie'\n",
      "','\n",
      "'Lacie'\n",
      "'and'\n",
      "'Tillie'\n",
      "';\\nand they lived at the bottom of a well.'\n",
      "'...'\n"
     ]
    }
   ],
   "source": [
    "for string in soup.stripped_strings:\n",
    "    print(repr(string))\n",
    "# 全部是空格的行会被忽略掉,段首和段末的空白会被删除"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 父节点\n",
    "\n",
    "继续分析文档树,每个tag或字符串都有父节点:被包含在某个tag中"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### .parent\n",
    "\n",
    "通过 .parent 属性来获取某个元素的父节点.在例子“爱丽丝”的文档中,<head>标签是<title>标签的父节点:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<title>The Dormouse's story</title>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_tag = soup.title\n",
    "title_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<head><title>The Dormouse's story</title></head>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_tag.parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The Dormouse's story\""
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_tag.string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<title>The Dormouse's story</title>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 文档title的字符串也有父节点: <title>标签\n",
    "title_tag.string.parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html><head><title>The Dormouse's story</title></head>\n",
      "<body><p class=\"title\"><b>The Dormouse's story</b></p>\n",
      "<p class=\"story\">Once upon a time there were three little sisters; and their names were\n",
      "<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>,\n",
      "<a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a> and\n",
      "<a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>;\n",
      "and they lived at the bottom of a well.</p>\n",
      "<p class=\"story\">...</p>\n",
      "</body></html>\n",
      "<class 'bs4.BeautifulSoup'>\n"
     ]
    }
   ],
   "source": [
    "# 文档的顶层节点比如<html>的父节点是 BeautifulSoup 对象:\n",
    "html_tag = soup.html\n",
    "print(html_tag)\n",
    "print(type(html_tag.parent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "# BeautifulSoup 对象的 .parent 是None:\n",
    "print(soup.parent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### .parents\n",
    "\n",
    "通过元素的 .parents 属性可以递归得到元素的所有父辈节点,下面的例子使用了 .parents 方法遍历了\\<a>标签到根节点的所有节点."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "link = soup.a\n",
    "link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p\n",
      "body\n",
      "html\n",
      "[document]\n"
     ]
    }
   ],
   "source": [
    "for parent in link.parents:\n",
    "    if parent is None:\n",
    "        ...\n",
    "        # print(parent)\n",
    "    else:\n",
    "        print(parent.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 兄弟节点\n",
    "\n",
    "看一段简单的例子:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html>\n",
      " <body>\n",
      "  <a>\n",
      "   <b>\n",
      "    text1\n",
      "   </b>\n",
      "   <c>\n",
      "    text2\n",
      "   </c>\n",
      "  </a>\n",
      " </body>\n",
      "</html>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sibling_soup = BeautifulSoup(\"<a><b>text1</b><c>text2</c></b></a>\")\n",
    "print(sibling_soup.prettify())\n",
    "# 因为<b>标签和<c>标签是同一层:他们是同一个元素的子节点,所以<b>和<c>可以被称为兄弟节点.\n",
    "# 一段文档以标准格式输出时,兄弟节点有相同的缩进级别.在代码中也可以使用这种关系."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### .next_sibling 和 .previous_sibling\n",
    "\n",
    "在文档树中,使用 .next_sibling 和 .previous_sibling 属性来查询兄弟节点:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<c>text2</c>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sibling_soup.b.next_sibling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<b>text1</b>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sibling_soup.c.previous_sibling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "# <b>标签有 .next_sibling 属性,但是没有 .previous_sibling 属性,因为<b>标签在同级节点中是第一个.\n",
    "print(sibling_soup.b.previous_sibling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "# 同理,<c>标签有 .previous_sibling 属性,却没有 .next_sibling 属性:\n",
    "print(sibling_soup.c.next_sibling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text1\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# 例子中的字符串“text1”和“text2”不是兄弟节点,因为它们的父节点不同:\n",
    "print(sibling_soup.b.string)\n",
    "print(sibling_soup.b.string.next_sibling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n<a href=\"http://example.com/elsie\" class=\"sister\" id=\"link1\">Elsie</a>\\n<a href=\"http://example.com/lacie\" class=\"sister\" id=\"link2\">Lacie</a>\\n<a href=\"http://example.com/tillie\" class=\"sister\" id=\"link3\">Tillie</a>\\n'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 实际文档中的tag的 .next_sibling 和 .previous_sibling 属性通常是字符串或空白. 看看“爱丽丝”文档:\n",
    "\n",
    "\"\"\"\n",
    "<a href=\"http://example.com/elsie\" class=\"sister\" id=\"link1\">Elsie</a>\n",
    "<a href=\"http://example.com/lacie\" class=\"sister\" id=\"link2\">Lacie</a>\n",
    "<a href=\"http://example.com/tillie\" class=\"sister\" id=\"link3\">Tillie</a>\n",
    "\"\"\"\n",
    "\n",
    "# 如果以为第一个<a>标签的 .next_sibling 结果是第二个<a>标签,那就错了,真实结果是第一个<a>标签和第二个<a>标签之间的顿号和换行符:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "link = soup.a\n",
    "link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "',\\n'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 如果以为第一个<a>标签的 .next_sibling 结果是第二个<a>标签,那就错了,真实结果是第一个<a>标签和第二个<a>标签之间的顿号和换行符:\n",
    "link.next_sibling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 第二个<a>标签是顿号的 .next_sibling 属性:\n",
    "link.next_sibling.next_sibling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### .next_siblings 和 .previous_siblings\n",
    "\n",
    "通过 .next_siblings 和 .previous_siblings 属性可以对当前节点的兄弟节点迭代输出:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "',\\n'\n",
      "<a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>\n",
      "' and\\n'\n",
      "<a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>\n",
      "';\\nand they lived at the bottom of a well.'\n"
     ]
    }
   ],
   "source": [
    "for sibling in soup.a.next_siblings:\n",
    "    print(repr(sibling))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "' and\\n'\n",
      "<a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>\n",
      "',\\n'\n",
      "<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>\n",
      "'Once upon a time there were three little sisters; and their names were\\n'\n"
     ]
    }
   ],
   "source": [
    "for sibling in soup.find(id=\"link3\").previous_siblings:\n",
    "    print(repr(sibling))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 回退和前进\n",
    "\n",
    "看一下“爱丽丝” 文档:\n",
    "\n",
    "```html\n",
    "<html><head><title>The Dormouse's story</title></head>\n",
    "<p class=\"title\"><b>The Dormouse's story</b></p>\n",
    "```\n",
    "\n",
    "HTML解析器把这段字符串转换成一连串的事件: “打开\\<html>标签”,”打开一个\\<head>标签”,”打开一个\\<title>标签”,”添加一段字符串”,”关闭\\<title>标签”,”打开\\<p>标签”,等等.Beautiful Soup提供了重现解析器初始化过程的方法."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### .next_element 和 .previous_element\n",
    "\n",
    ".next_element 属性指向解析过程中下一个被解析的对象(字符串或tag),结果可能与 .next_sibling 相同,但通常是不一样的.\n",
    "\n",
    "这是“爱丽丝”文档中最后一个\\<a>标签,它的 .next_sibling 结果是一个字符串,因为当前的解析过程因为当前的解析过程因为遇到了\\<a>标签而中断了:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_a_tag = soup.find('a', id='link3')\n",
    "last_a_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "';\\nand they lived at the bottom of a well.'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_a_tag.next_sibling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tillie'"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 但这个<a>标签的 .next_element 属性结果是在<a>标签被解析之后的解析内容,不是<a>标签后的句子部分,应该是字符串”Tillie”:\n",
    "last_a_tag.next_element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' and\\n'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 这是因为在原始文档中,字符串“Tillie”在分号前出现,解析器先进入<a>标签,然后是字符串“Tillie”,\n",
    "# 然后关闭</a>标签,然后是分号和剩余部分.分号与<a>标签在同一层级,但是字符串“Tillie”会被先解析.\n",
    "\n",
    "# .previous_element 属性刚好与 .next_element 相反,它指向当前被解析的对象的前一个解析对象:\n",
    "last_a_tag.previous_element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_a_tag.previous_element.next_element"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### .next_elements 和 .previous_elements\n",
    "\n",
    "通过 .next_elements 和 .previous_elements 的迭代器就可以向前或向后访问文档的解析内容,就好像文档正在被解析一样:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Tillie'\n",
      "';\\nand they lived at the bottom of a well.'\n",
      "'\\n'\n",
      "<p class=\"story\">...</p>\n",
      "'...'\n",
      "'\\n'\n"
     ]
    }
   ],
   "source": [
    "for element in last_a_tag.next_elements:\n",
    "    print(repr(element))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 搜索文档树\n",
    "\n",
    "Beautiful Soup定义了很多搜索方法,这里着重介绍2个: find() 和 find_all() .其它方法的参数和用法类似,请读者举一反三.\n",
    "\n",
    "再以“爱丽丝”文档作为例子:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<html><head><title>The Dormouse's story</title></head>\n",
       "<body><p class=\"title\"><b>The Dormouse's story</b></p>\n",
       "<p class=\"story\">Once upon a time there were three little sisters; and their names were\n",
       "<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>,\n",
       "<a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a> and\n",
       "<a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>;\n",
       "and they lived at the bottom of a well.</p>\n",
       "<p class=\"story\">...</p>\n",
       "</body></html>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html_doc = \"\"\"\n",
    "<html><head><title>The Dormouse's story</title></head>\n",
    "\n",
    "<p class=\"title\"><b>The Dormouse's story</b></p>\n",
    "\n",
    "<p class=\"story\">Once upon a time there were three little sisters; and their names were\n",
    "<a href=\"http://example.com/elsie\" class=\"sister\" id=\"link1\">Elsie</a>,\n",
    "<a href=\"http://example.com/lacie\" class=\"sister\" id=\"link2\">Lacie</a> and\n",
    "<a href=\"http://example.com/tillie\" class=\"sister\" id=\"link3\">Tillie</a>;\n",
    "and they lived at the bottom of a well.</p>\n",
    "\n",
    "<p class=\"story\">...</p>\n",
    "\"\"\"\n",
    "\n",
    "soup = BeautifulSoup(html_doc)\n",
    "soup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 过滤器\n",
    "\n",
    "介绍 find_all() 方法前,先介绍一下过滤器的类型,这些过滤器贯穿整个搜索的API.过滤器可以被用在tag的name中,节点的属性中,字符串中或他们的混合中."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 字符串\n",
    "\n",
    "最简单的过滤器是字符串.在搜索方法中传入一个字符串参数,Beautiful Soup会查找与字符串完整匹配的内容,下面的例子用于查找文档中所有的<b>标签:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<b>The Dormouse's story</b>]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all('b')\n",
    "# 如果传入字节码参数,Beautiful Soup会当作UTF-8编码,可以传入一段Unicode 编码来避免Beautiful Soup解析编码出错"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 正则表达式\n",
    "\n",
    "如果传入正则表达式作为参数,Beautiful Soup会通过正则表达式的 match() 来匹配内容.下面例子中找出所有以b开头的标签,这表示<body>和<b>标签都应该被找到:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "re.compile(r'^b', re.UNICODE)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "# 开头为b\n",
    "re.compile(\"^b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "body\n",
      "b\n"
     ]
    }
   ],
   "source": [
    "for tag in soup.find_all(re.compile(\"^b\")):\n",
    "    print(tag.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "html\n",
      "title\n"
     ]
    }
   ],
   "source": [
    "# 下面代码找出所有名字中包含”t”的标签:\n",
    "for tag in soup.find_all(re.compile(\"t\")):\n",
    "    print(tag.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 列表\n",
    "\n",
    "如果传入列表参数,Beautiful Soup会将与列表中任一元素匹配的内容返回.下面代码找到文档中所有\\<a>标签和\\<b>标签:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<b>The Dormouse's story</b>,\n",
       " <a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>,\n",
       " <a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>,\n",
       " <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all([\"a\", \"b\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### True\n",
    "\n",
    "True 可以匹配任何值,下面代码查找到所有的tag,但是不会返回字符串节点"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "html\n",
      "head\n",
      "title\n",
      "body\n",
      "p\n",
      "b\n",
      "p\n",
      "a\n",
      "a\n",
      "a\n",
      "p\n"
     ]
    }
   ],
   "source": [
    "for tag in soup.find_all(True):\n",
    "    print(tag.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 方法\n",
    "\n",
    "如果没有合适过滤器,那么还可以定义一个方法,方法只接受一个元素参数,如果这个方法返回 True 表示当前元素匹配并且被找到,如果不是则反回 False\n",
    "\n",
    "下面方法校验了当前元素,如果包含 class 属性却不包含 id 属性,那么将返回 True:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_class_but_no_id(tag):\n",
    "    return tag.has_attr('class') and not tag.has_attr('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p class=\"title\"><b>The Dormouse's story</b></p>,\n",
       " <p class=\"story\">Once upon a time there were three little sisters; and their names were\n",
       " <a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>,\n",
       " <a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a> and\n",
       " <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>;\n",
       " and they lived at the bottom of a well.</p>,\n",
       " <p class=\"story\">...</p>]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 将这个方法作为参数传入 find_all() 方法,将得到所有<p>标签:\n",
    "soup.find_all(has_class_but_no_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p\n",
      "a\n",
      "a\n",
      "a\n",
      "p\n"
     ]
    }
   ],
   "source": [
    "# 返回结果中只有<p>标签没有<a>标签,因为<a>标签还定义了”id”,没有返回<html>和<head>,因为<html>和<head>中没有定义”class”属性.\n",
    "# 下面代码找到所有被文字包含的节点内容:\n",
    "from bs4 import NavigableString\n",
    "def surrounded_by_strings(tag):\n",
    "    return (isinstance(tag.next_element, NavigableString)\n",
    "            and isinstance(tag.previous_element, NavigableString))\n",
    "\n",
    "for tag in soup.find_all(surrounded_by_strings):\n",
    "    print(tag.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## find_all()\n",
    "\n",
    "`find_all(name, attrs, recursive, text, **kwargs)`\n",
    "\n",
    "`find_all()` 方法搜索当前tag的所有tag子节点,并判断是否符合过滤器的条件.这里有几个例子:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<title>The Dormouse's story</title>]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all(name='title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p class=\"title\"><b>The Dormouse's story</b></p>]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all(name=\"p\", attrs=\"title\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>,\n",
       " <a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>,\n",
       " <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all(name=\"a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all(id=\"link2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Once upon a time there were three little sisters; and their names were\\n'"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "soup.find(string=re.compile(\"sisters\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### name 参数\n",
    "\n",
    "name 参数可以查找所有名字为 name 的tag,字符串对象会被自动忽略掉.\n",
    "\n",
    "重申: 搜索 name 参数的值可以使任一类型的 过滤器 ,字符窜,正则表达式,列表,方法或是 True .\n",
    "\n",
    "简单的用法如下:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<title>The Dormouse's story</title>]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all(name=\"title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### keyword 参数\n",
    "\n",
    "如果一个指定名字的参数不是搜索内置的参数名,搜索时会把该参数当作指定名字tag的属性来搜索,如果包含一个名字为 id 的参数,Beautiful Soup会搜索每个tag的”id”属性."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all(id='link2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 如果传入 href 参数,Beautiful Soup会搜索每个tag的”href”属性:\n",
    "soup.find_all(href=re.compile(\"elsie\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>,\n",
       " <a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>,\n",
       " <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 搜索指定名字的属性时可以使用的参数值包括 字符串 , 正则表达式 , 列表, True .\n",
    "# 下面的例子在文档树中查找所有包含 id 属性的tag,无论 id 的值是什么:\n",
    "soup.find_all(id=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用多个指定名字的参数可以同时过滤tag的多个属性:\n",
    "soup.find_all(href=re.compile(\"elsie\"), id='link1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_soup = BeautifulSoup('<div data-foo=\"value\">foo!</div>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "expression cannot contain assignment, perhaps you meant \"==\"? (2788511272.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[114], line 2\u001b[1;36m\u001b[0m\n\u001b[1;33m    data_soup.find_all(data-foo=\"value\")\u001b[0m\n\u001b[1;37m                       ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m expression cannot contain assignment, perhaps you meant \"==\"?\n"
     ]
    }
   ],
   "source": [
    "# 有些tag属性在搜索不能使用,比如HTML5中的 data-* 属性:\n",
    "data_soup.find_all(data-foo=\"value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<div data-foo=\"value\">foo!</div>]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 但是可以通过 find_all() 方法的 attrs 参数定义一个字典参数来搜索包含特殊属性的tag:\n",
    "data_soup.find_all(attrs={\"data-foo\": \"value\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 按CSS搜索\n",
    "\n",
    "按照CSS类名搜索tag的功能非常实用,但标识CSS类名的关键字 class 在Python中是保留字,使用 class 做参数会导致语法错误.从Beautiful Soup的4.1.1版本开始,可以通过 class_ 参数搜索有指定CSS类名的tag:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>,\n",
       " <a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>,\n",
       " <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all(\"a\", class_=\"sister\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p class=\"title\"><b>The Dormouse's story</b></p>]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# class_ 参数同样接受不同类型的 过滤器 ,字符串,正则表达式,方法或 True :\n",
    "soup.find_all(class_=re.compile(\"itl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>,\n",
       " <a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>,\n",
       " <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def has_six_characters(css_class):\n",
    "    return css_class is not None and len(css_class) == 6\n",
    "soup.find_all(class_=has_six_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p class=\"body strikeout\"></p>]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tag的 class 属性是 多值属性 .按照CSS类名搜索tag时,可以分别搜索tag中的每个CSS类名:\n",
    "css_soup = BeautifulSoup('<p class=\"body strikeout\"></p>')\n",
    "css_soup.find_all(\"p\", class_=\"strikeout\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p class=\"body strikeout\"></p>]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "css_soup.find_all(\"p\", class_=\"body\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p class=\"body strikeout\"></p>]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 搜索 class 属性时也可以通过CSS值完全匹配:\n",
    "css_soup.find_all(\"p\", class_=\"body strikeout\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>,\n",
       " <a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>,\n",
       " <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 完全匹配 class 的值时,如果CSS类名的顺序与实际不符,将搜索不到结果:\n",
    "soup.find_all(\"a\", attrs={\"class\": \"sister\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### string 参数\n",
    "\n",
    "通过 string 参数可以搜搜文档中的字符串内容.与 name 参数的可选值一样, string 参数接受 字符串 , 正则表达式 , 列表, True . 看例子:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Elsie']"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all(string=\"Elsie\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Elsie', 'Lacie', 'Tillie']"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all(string=[\"Tillie\", \"Elsie\", \"Lacie\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"The Dormouse's story\", \"The Dormouse's story\"]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all(string=re.compile(\"Dormouse\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"The Dormouse's story\",\n",
       " \"The Dormouse's story\",\n",
       " 'Elsie',\n",
       " 'Lacie',\n",
       " 'Tillie',\n",
       " '...']"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def is_the_only_string_within_a_tag(s):\n",
    "    \"\"\"Return True if this string is the only child of its parent tag.\"\"\"\n",
    "    return (s == s.parent.string)\n",
    "soup.find_all(string=is_the_only_string_within_a_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 虽然 text 参数用于搜索字符串,还可以与其它参数混合使用来过滤tag.Beautiful Soup会找到 .string 方法与 text 参数值相符的tag.下面代码用来搜索内容里面包含“Elsie”的<a>标签:\n",
    "soup.find_all(name=\"a\", string=\"Elsie\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### limit 参数\n",
    "\n",
    "`find_all()` 方法返回全部的搜索结构,如果文档树很大那么搜索会很慢.如果我们不需要全部结果,可以使用 limit 参数限制返回结果的数量.效果与SQL中的limit关键字类似,当搜索到的结果数量达到 limit 的限制时,就停止搜索返回结果.\n",
    "\n",
    "文档树中有3个tag符合搜索条件,但结果只返回了2个,因为我们限制了返回数量:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>,\n",
       " <a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all(name=\"a\", limit=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### recursive 参数\n",
    "\n",
    "调用tag的 `find_all()` 方法时,Beautiful Soup会检索当前tag的所有子孙节点,如果只想搜索tag的直接子节点,可以使用参数 `recursive=False` .\n",
    "\n",
    "一段简单的文档:\n",
    "```html\n",
    "<html>\n",
    " <head>\n",
    "  <title>\n",
    "   The Dormouse's story\n",
    "  </title>\n",
    " </head>\n",
    "...\n",
    "```\n",
    "是否使用 recursive 参数的搜索结果:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<title>The Dormouse's story</title>]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.html.find_all(name='title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.html.find_all(name='title', recursive=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 像调用 find_all() 一样调用tag\n",
    "\n",
    "find_all() 几乎是Beautiful Soup中最常用的搜索方法,所以我们定义了它的简写方法. BeautifulSoup 对象和 tag 对象可以被当作一个方法来使用,这个方法的执行结果与调用这个对象的 find_all() 方法相同,下面两行代码是等价的:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>,\n",
       " <a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>,\n",
       " <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all(name=\"a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>,\n",
       " <a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>,\n",
       " <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup(name=\"a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"The Dormouse's story\"]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 这两行代码也是等价的:\n",
    "soup.title.find_all(string=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"The Dormouse's story\"]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.title(string=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## find()\n",
    "\n",
    "`find(name, attrs, recursive, text, **kwargs)`\n",
    "\n",
    "find_all() 方法将返回文档中符合条件的所有tag,尽管有时候我们只想得到一个结果.比如文档中只有一个<body>标签,那么使用 find_all() 方法来查找<body>标签就不太合适, 使用 find_all 方法并设置 limit=1 参数不如直接使用 find() 方法.下面两行代码是等价的:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<title>The Dormouse's story</title>]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all(name='title', limit=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<title>The Dormouse's story</title>"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find(name='title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "# 唯一的区别是 find_all() 方法的返回结果是值包含一个元素的列表,而 find() 方法直接返回结果.\n",
    "# find_all() 方法没有找到目标是返回空列表, find() 方法找不到目标时,返回 None .\n",
    "print(soup.find(name=\"nosuchtag\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<title>The Dormouse's story</title>"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# soup.head.title 是 tag的名字 方法的简写.这个简写的原理就是多次调用当前tag的 find() 方法:\n",
    "soup.head.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<title>The Dormouse's story</title>"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find(\"head\").find(\"title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## find_parents() 和 find_parent()\n",
    "\n",
    "`find_parents(name, attrs, recursive, text, **kwargs)`\n",
    "\n",
    "`find_parent(name, attrs, recursive, text, **kwargs)`\n",
    "\n",
    "我们已经用了很大篇幅来介绍 find_all() 和 find() 方法,Beautiful Soup中还有10个用于搜索的API.它们中的五个用的是与 find_all() 相同的搜索参数,另外5个与 find() 方法的搜索参数类似.区别仅是它们搜索文档的不同部分.\n",
    "\n",
    "记住: find_all() 和 find() 只搜索当前节点的所有子节点,孙子节点等. find_parents() 和 find_parent() 用来搜索当前节点的父辈节点,搜索方法与普通tag的搜索方法相同,搜索文档搜索文档包含的内容. 我们从一个文档中的一个叶子节点开始:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Lacie'"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_string = soup.find(string=\"Lacie\")\n",
    "a_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_string.find_parents(name=\"a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<p class=\"story\">Once upon a time there were three little sisters; and their names were\n",
       "<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>,\n",
       "<a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a> and\n",
       "<a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>;\n",
       "and they lived at the bottom of a well.</p>"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_string.find_parent(name=\"p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_string.find_parents(name=\"p\", class_=\"title\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 文档中的一个<a>标签是是当前叶子节点的直接父节点,所以可以被找到.还有一个<p>标签,是目标叶子节点的间接父辈节点,\n",
    "# 所以也可以被找到.包含class值为”title”的<p>标签不是不是目标叶子节点的父辈节点,所以通过 find_parents() 方法搜索不到.\n",
    "\n",
    "# find_parent() 和 find_parents() 方法会让人联想到 .parent 和 .parents 属性.\n",
    "# 它们之间的联系非常紧密.搜索父辈节点的方法实际上就是对 .parents 属性的迭代搜索."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## find_next_siblings() 合 find_next_sibling()\n",
    "\n",
    "`find_next_siblings(name, attrs, recursive, text, **kwargs)`\n",
    "\n",
    "`find_next_sibling(name, attrs, recursive, text, **kwargs)`\n",
    "\n",
    "这2个方法通过 .next_siblings 属性对当tag的所有后面解析的兄弟tag节点进行迭代, find_next_siblings() 方法返回所有符合条件的后面的兄弟节点, find_next_sibling() 只返回符合条件的后面的第一个tag节点."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_link = soup.a\n",
    "first_link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>,\n",
       " <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_link.find_next_siblings(name=\"a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<p class=\"story\">Once upon a time there were three little sisters; and their names were\n",
       "<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>,\n",
       "<a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a> and\n",
       "<a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>;\n",
       "and they lived at the bottom of a well.</p>"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_story_paragraph = soup.find(name=\"p\", attrs=\"story\")\n",
    "first_story_paragraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<p class=\"story\">...</p>"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_story_paragraph.find_next_sibling(name=\"p\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## find_previous_siblings() 和 find_previous_sibling()\n",
    "\n",
    "`find_previous_siblings(name, attrs, recursive, text, **kwargs)`\n",
    "\n",
    "`find_previous_sibling(name, attrs, recursive, text, **kwargs)`\n",
    "\n",
    "这2个方法通过 .previous_siblings 属性对当前tag的前面解析的兄弟tag节点进行迭代, find_previous_siblings() 方法返回所有符合条件的前面的兄弟节点, find_previous_sibling() 方法返回第一个符合条件的前面的兄弟节点:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_link = soup.find(name=\"a\", id=\"link3\")\n",
    "last_link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>,\n",
       " <a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_link.find_previous_siblings(name=\"a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<p class=\"story\">Once upon a time there were three little sisters; and their names were\n",
       "<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>,\n",
       "<a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a> and\n",
       "<a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>;\n",
       "and they lived at the bottom of a well.</p>"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_story_paragraph = soup.find(name=\"p\", attrs=\"story\")\n",
    "first_story_paragraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<p class=\"title\"><b>The Dormouse's story</b></p>"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_story_paragraph.find_previous_sibling(name=\"p\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## find_all_next() 和 find_next()\n",
    "\n",
    "`find_all_next(name, attrs, recursive, text, **kwargs)`\n",
    "\n",
    "`find_next(name, attrs, recursive, text, **kwargs)`\n",
    "\n",
    "这2个方法通过 .next_elements 属性对当前tag的之后的tag和字符串进行迭代, find_all_next() 方法返回所有符合条件的节点, find_next() 方法返回第一个符合条件的节点:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_link = soup.a\n",
    "first_link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Elsie',\n",
       " ',\\n',\n",
       " 'Lacie',\n",
       " ' and\\n',\n",
       " 'Tillie',\n",
       " ';\\nand they lived at the bottom of a well.',\n",
       " '\\n',\n",
       " '...',\n",
       " '\\n']"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_link.find_all_next(string=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<p class=\"story\">...</p>"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_link.find_next(name=\"p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 第一个例子中,字符串 “Elsie”也被显示出来,尽管它被包含在我们开始查找的<a>标签的里面.\n",
    "# 第二个例子中,最后一个<p>标签也被显示出来,尽管它与我们开始查找位置的<a>标签不属于同一部分.\n",
    "# 例子中,搜索的重点是要匹配过滤器的条件,并且在文档中出现的顺序而不是开始查找的元素的位置."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## find_all_previous() 和 find_previous()\n",
    "\n",
    "`find_all_previous(name, attrs, recursive, text, **kwargs)`\n",
    "\n",
    "`find_previous(name, attrs, recursive, text, **kwargs)`\n",
    "\n",
    "这2个方法通过 .previous_elements 属性对当前节点前面 的tag和字符串进行迭代, find_all_previous() 方法返回所有符合条件的节点, find_previous() 方法返回第一个符合条件的节点."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_link = soup.a\n",
    "first_link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p class=\"story\">Once upon a time there were three little sisters; and their names were\n",
       " <a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>,\n",
       " <a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a> and\n",
       " <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>;\n",
       " and they lived at the bottom of a well.</p>,\n",
       " <p class=\"title\"><b>The Dormouse's story</b></p>]"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_link.find_all_previous(name=\"p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<title>The Dormouse's story</title>"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_link.find_previous(name=\"title\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find_all_previous(\"p\") 返回了文档中的第一段(class=”title”的那段),但还返回了第二段,\n",
    "# <p>标签包含了我们开始查找的<a>标签.不要惊讶,这段代码的功能是查找所有出现在指定<a>标签之前的<p>标签,\n",
    "# 因为这个<p>标签包含了开始的<a>标签,所以<p>标签一定是在<a>之前出现的."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSS选择器\n",
    "\n",
    "Beautiful Soup支持大部分的CSS选择器 ,在 Tag 或 BeautifulSoup 对象的 .select() 方法中传入字符串参数,即可使用CSS选择器的语法找到tag:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<title>The Dormouse's story</title>]"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.select(selector=\"title\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "ename": "SelectorSyntaxError",
     "evalue": "Invalid character '(' position 13\n  line 1:\np nth-of-type(3)\n             ^",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mSelectorSyntaxError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Administrator\\Desktop\\self\\PythonLearn\\01\\BeautifulSoup\\bs4.ipynb 单元格 223\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Administrator/Desktop/self/PythonLearn/01/BeautifulSoup/bs4.ipynb#Y435sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m soup\u001b[39m.\u001b[39;49mselect(selector\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mp nth-of-type(3)\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[1;32md:\\miniconda3\\envs\\pytorch\\Lib\\site-packages\\bs4\\element.py:2111\u001b[0m, in \u001b[0;36mTag.select\u001b[1;34m(self, selector, namespaces, limit, **kwargs)\u001b[0m\n\u001b[0;32m   2091\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mselect\u001b[39m(\u001b[39mself\u001b[39m, selector, namespaces\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, limit\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m   2092\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Perform a CSS selection operation on the current element.\u001b[39;00m\n\u001b[0;32m   2093\u001b[0m \n\u001b[0;32m   2094\u001b[0m \u001b[39m    This uses the SoupSieve library.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2109\u001b[0m \u001b[39m    :rtype: bs4.element.ResultSet\u001b[39;00m\n\u001b[0;32m   2110\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2111\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcss\u001b[39m.\u001b[39;49mselect(selector, namespaces, limit, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32md:\\miniconda3\\envs\\pytorch\\Lib\\site-packages\\bs4\\css.py:162\u001b[0m, in \u001b[0;36mCSS.select\u001b[1;34m(self, select, namespaces, limit, flags, **kwargs)\u001b[0m\n\u001b[0;32m    158\u001b[0m \u001b[39mif\u001b[39;00m limit \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    159\u001b[0m     limit \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m    161\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_rs(\n\u001b[1;32m--> 162\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapi\u001b[39m.\u001b[39;49mselect(\n\u001b[0;32m    163\u001b[0m         select, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtag, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_ns(namespaces, select), limit, flags,\n\u001b[0;32m    164\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[0;32m    165\u001b[0m     )\n\u001b[0;32m    166\u001b[0m )\n",
      "File \u001b[1;32md:\\miniconda3\\envs\\pytorch\\Lib\\site-packages\\soupsieve\\__init__.py:147\u001b[0m, in \u001b[0;36mselect\u001b[1;34m(select, tag, namespaces, limit, flags, custom, **kwargs)\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mselect\u001b[39m(\n\u001b[0;32m    136\u001b[0m     select: \u001b[39mstr\u001b[39m,\n\u001b[0;32m    137\u001b[0m     tag: bs4\u001b[39m.\u001b[39mTag,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    143\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any\n\u001b[0;32m    144\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mlist\u001b[39m[bs4\u001b[39m.\u001b[39mTag]:\n\u001b[0;32m    145\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Select the specified tags.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 147\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mcompile\u001b[39;49m(select, namespaces, flags, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\u001b[39m.\u001b[39mselect(tag, limit)\n",
      "File \u001b[1;32md:\\miniconda3\\envs\\pytorch\\Lib\\site-packages\\soupsieve\\__init__.py:65\u001b[0m, in \u001b[0;36mcompile\u001b[1;34m(pattern, namespaces, flags, custom, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCannot process \u001b[39m\u001b[39m'\u001b[39m\u001b[39mcustom\u001b[39m\u001b[39m'\u001b[39m\u001b[39m argument on a compiled selector list\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     63\u001b[0m     \u001b[39mreturn\u001b[39;00m pattern\n\u001b[1;32m---> 65\u001b[0m \u001b[39mreturn\u001b[39;00m cp\u001b[39m.\u001b[39;49m_cached_css_compile(\n\u001b[0;32m     66\u001b[0m     pattern,\n\u001b[0;32m     67\u001b[0m     ct\u001b[39m.\u001b[39;49mNamespaces(namespaces) \u001b[39mif\u001b[39;49;00m namespaces \u001b[39mis\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m \u001b[39melse\u001b[39;49;00m namespaces,\n\u001b[0;32m     68\u001b[0m     ct\u001b[39m.\u001b[39;49mCustomSelectors(custom) \u001b[39mif\u001b[39;49;00m custom \u001b[39mis\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m \u001b[39melse\u001b[39;49;00m custom,\n\u001b[0;32m     69\u001b[0m     flags\n\u001b[0;32m     70\u001b[0m )\n",
      "File \u001b[1;32md:\\miniconda3\\envs\\pytorch\\Lib\\site-packages\\soupsieve\\css_parser.py:208\u001b[0m, in \u001b[0;36m_cached_css_compile\u001b[1;34m(pattern, namespaces, custom, flags)\u001b[0m\n\u001b[0;32m    199\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Cached CSS compile.\"\"\"\u001b[39;00m\n\u001b[0;32m    201\u001b[0m custom_selectors \u001b[39m=\u001b[39m process_custom(custom)\n\u001b[0;32m    202\u001b[0m \u001b[39mreturn\u001b[39;00m cm\u001b[39m.\u001b[39mSoupSieve(\n\u001b[0;32m    203\u001b[0m     pattern,\n\u001b[0;32m    204\u001b[0m     CSSParser(\n\u001b[0;32m    205\u001b[0m         pattern,\n\u001b[0;32m    206\u001b[0m         custom\u001b[39m=\u001b[39;49mcustom_selectors,\n\u001b[0;32m    207\u001b[0m         flags\u001b[39m=\u001b[39;49mflags\n\u001b[1;32m--> 208\u001b[0m     )\u001b[39m.\u001b[39;49mprocess_selectors(),\n\u001b[0;32m    209\u001b[0m     namespaces,\n\u001b[0;32m    210\u001b[0m     custom,\n\u001b[0;32m    211\u001b[0m     flags\n\u001b[0;32m    212\u001b[0m )\n",
      "File \u001b[1;32md:\\miniconda3\\envs\\pytorch\\Lib\\site-packages\\soupsieve\\css_parser.py:1129\u001b[0m, in \u001b[0;36mCSSParser.process_selectors\u001b[1;34m(self, index, flags)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mprocess_selectors\u001b[39m(\u001b[39mself\u001b[39m, index: \u001b[39mint\u001b[39m \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m, flags: \u001b[39mint\u001b[39m \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m ct\u001b[39m.\u001b[39mSelectorList:\n\u001b[0;32m   1127\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Process selectors.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1129\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparse_selectors(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mselector_iter(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpattern), index, flags)\n",
      "File \u001b[1;32md:\\miniconda3\\envs\\pytorch\\Lib\\site-packages\\soupsieve\\css_parser.py:965\u001b[0m, in \u001b[0;36mCSSParser.parse_selectors\u001b[1;34m(self, iselector, index, flags)\u001b[0m\n\u001b[0;32m    963\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    964\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m--> 965\u001b[0m         key, m \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(iselector)\n\u001b[0;32m    967\u001b[0m         \u001b[39m# Handle parts\u001b[39;00m\n\u001b[0;32m    968\u001b[0m         \u001b[39mif\u001b[39;00m key \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mat_rule\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[1;32md:\\miniconda3\\envs\\pytorch\\Lib\\site-packages\\soupsieve\\css_parser.py:1122\u001b[0m, in \u001b[0;36mCSSParser.selector_iter\u001b[1;34m(self, pattern)\u001b[0m\n\u001b[0;32m   1120\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1121\u001b[0m             msg \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mInvalid character \u001b[39m\u001b[39m{\u001b[39;00mc\u001b[39m!r}\u001b[39;00m\u001b[39m position \u001b[39m\u001b[39m{\u001b[39;00mindex\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m-> 1122\u001b[0m         \u001b[39mraise\u001b[39;00m SelectorSyntaxError(msg, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpattern, index)\n\u001b[0;32m   1123\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdebug:  \u001b[39m# pragma: no cover\u001b[39;00m\n\u001b[0;32m   1124\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m## END PARSING\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mSelectorSyntaxError\u001b[0m: Invalid character '(' position 13\n  line 1:\np nth-of-type(3)\n             ^"
     ]
    }
   ],
   "source": [
    "soup.select(selector=\"p nth-of-type(3)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>,\n",
       " <a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>,\n",
       " <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>]"
      ]
     },
     "execution_count": 605,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 通过tag标签逐层查找:\n",
    "soup.select(selector=\"body a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<title>The Dormouse's story</title>]"
      ]
     },
     "execution_count": 606,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.select(selector=\"html head title\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<title>The Dormouse's story</title>]"
      ]
     },
     "execution_count": 607,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 找到某个tag标签下的直接子标签:\n",
    "soup.select(selector=\"head > title\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>,\n",
       " <a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>,\n",
       " <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>]"
      ]
     },
     "execution_count": 608,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.select(selector=\"p > a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>]"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.select(selector=\"p > a:nth-of-type(2)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>]"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.select(selector=\"p > #link1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.select(selector=\"body > a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>,\n",
       " <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>]"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 找到兄弟节点标签:\n",
    "soup.select(selector=\"#link1 ~ .sister\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>]"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.select(selector=\"#link1 + .sister\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>,\n",
       " <a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>,\n",
       " <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>]"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 通过CSS的类名查找:\n",
    "soup.select(selector=\".sister\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>,\n",
       " <a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>,\n",
       " <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>]"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.select(selector=\"[class~=sister]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>]"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 通过tag的id查找:\n",
    "soup.select(selector=\"#link1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>]"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.select(selector=\"a#link2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>,\n",
       " <a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>,\n",
       " <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>]"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 通过是否存在某个属性来查找:\n",
    "soup.select(selector='a[href]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>]"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 通过属性的值来查找:\n",
    "soup.select(selector='a[href=\"http://example.com/elsie\"]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>,\n",
       " <a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>,\n",
       " <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>]"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.select(selector='a[href^=\"http://example.com/\"]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>]"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.select(selector='a[href$=\"tillie\"]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>]"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.select(selector='a[href*=\".com/el\"]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p lang=\"en\">Hello</p>,\n",
       " <p lang=\"en-us\">Howdy, y'all</p>,\n",
       " <p lang=\"en-gb\">Pip-pip, old fruit</p>]"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 通过语言设置来查找:\n",
    "multilingual_markup = \"\"\"\n",
    " <p lang=\"en\">Hello</p>\n",
    " <p lang=\"en-us\">Howdy, y'all</p>\n",
    " <p lang=\"en-gb\">Pip-pip, old fruit</p>\n",
    " <p lang=\"fr\">Bonjour mes amis</p>\n",
    "\"\"\"\n",
    "multilingual_soup = BeautifulSoup(multilingual_markup)\n",
    "multilingual_soup.select(selector='p[lang|=en]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对于熟悉CSS选择器语法的人来说这是个非常方便的方法.Beautiful Soup也支持CSS选择器API,\n",
    "# 如果你仅仅需要CSS选择器的功能,那么直接使用 lxml 也可以,而且速度更快,支持更多的CSS选择器语法,\n",
    "# 但Beautiful Soup整合了CSS选择器的语法和自身方便使用API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 修改文档树\n",
    "\n",
    "Beautiful Soup的强项是文档树的搜索,但同时也可以方便的修改文档树"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 修改tag的名称和属性\n",
    "\n",
    "在 Attributes 的章节中已经介绍过这个功能,但是再看一遍也无妨. 重命名一个tag,改变属性的值,添加或删除属性:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<b class=\"boldest\">Extremely bold</b>"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup = BeautifulSoup('<b class=\"boldest\">Extremely bold</b>')\n",
    "tag = soup.b\n",
    "tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<blockquote class=\"verybold\" id=\"1\">Extremely bold</blockquote>"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag.name = \"blockquote\"\n",
    "tag['class'] = 'verybold'\n",
    "tag['id'] = 1\n",
    "tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<blockquote>Extremely bold</blockquote>"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del tag['class']\n",
    "del tag['id']\n",
    "tag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 修改 .string\n",
    "\n",
    "给tag的 .string 属性赋值,就相当于用当前的内容替代了原来的内容:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<html><body><a href=\"http://example.com/\">I linked to <i>example.com</i></a></body></html>"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "markup = '<a href=\"http://example.com/\">I linked to <i>example.com</i></a>'\n",
    "soup = BeautifulSoup(markup)\n",
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<a href=\"http://example.com/\">New link text.</a>"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag = soup.a\n",
    "tag.string = \"New link text.\"\n",
    "tag\n",
    "# 注意: 如果当前的tag包含了其它tag,那么给它的 .string 属性赋值会覆盖掉原有的所有内容包括子tag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## append()\n",
    "\n",
    "Tag.append() 方法想tag中添加内容,就好像Python的列表的 .append() 方法:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Foo']"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup = BeautifulSoup(\"<a>Foo</a>\")\n",
    "soup.a.contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<html><body><a>FooBar</a></body></html>"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.a.append(\"Bar\")\n",
    "soup\n",
    "# Foo 变为 FooBar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Foo', 'Bar']"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.a.contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BeautifulSoup.new_string() 和 .new_tag()\n",
    "\n",
    "如果想添加一段文本内容到文档中也没问题,可以调用Python的 append() 方法或调用工厂方法 BeautifulSoup.new_string() :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<b></b>"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup = BeautifulSoup(\"<b></b>\")\n",
    "tag = soup.b\n",
    "tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<b>Hello there</b>"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2种方式结果相同\n",
    "tag.append(\"Hello\")\n",
    "new_string = soup.new_string(\" there\")\n",
    "tag.append(new_string)\n",
    "tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello', ' there']"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag.contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<b>Hello there<!--Nice to see you.--></b>"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 如果想要创建一段注释,或 NavigableString 的任何子类,将子类作为 new_string() 方法的第二个参数传入:\n",
    "from bs4 import Comment\n",
    "new_comment = soup.new_string(\"Nice to see you.\", Comment)\n",
    "tag.append(new_comment)\n",
    "tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello', ' there', 'Nice to see you.']"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag.contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<b></b>"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 创建一个tag最好的方法是调用工厂方法 BeautifulSoup.new_tag():\n",
    "soup = BeautifulSoup(\"<b></b>\")\n",
    "original_tag = soup.b\n",
    "original_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<b><a href=\"http://www.example.com\"></a></b>"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 第一个参数作为tag的name,是必填,其它参数选填\n",
    "new_tag = soup.new_tag(\"a\", href=\"http://www.example.com\")\n",
    "original_tag.append(new_tag)\n",
    "original_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<b><a href=\"http://www.example.com\">Link text.</a></b>"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_tag.string = \"Link text.\"\n",
    "original_tag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## insert()\n",
    "\n",
    "Tag.insert() 方法与 Tag.append() 方法类似,区别是不会把新元素添加到父节点 .contents 属性的最后,而是把元素插入到指定的位置.与Python列表总的 .insert() 方法的用法下同:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<a href=\"http://example.com/\">I linked to <i>example.com</i></a>"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "markup = '<a href=\"http://example.com/\">I linked to <i>example.com</i></a>'\n",
    "soup = BeautifulSoup(markup)\n",
    "tag = soup.a\n",
    "tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I linked to ', <i>example.com</i>]"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag.contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<a href=\"http://example.com/\">I linked to but did not endorse <i>example.com</i></a>"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag.insert(1, \"but did not endorse \")\n",
    "tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I linked to ', 'but did not endorse ', <i>example.com</i>]"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag.contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## insert_before() 和 insert_after()\n",
    "\n",
    "insert_before() 方法在当前tag或文本节点前插入内容:\n",
    "\n",
    "insert_after() 方法在当前tag或文本节点后插入内容:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<b>stop</b>"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup = BeautifulSoup(\"<b>stop</b>\")\n",
    "soup.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<i></i>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<i>Don't</i>"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag = soup.new_tag(\"i\")\n",
    "print(tag)\n",
    "tag.string = \"Don't\"\n",
    "tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<b>stop</b>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<b><i>Don't</i>stop</b>"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(soup.b)\n",
    "soup.b.string.insert_before(tag)\n",
    "soup.b\n",
    "# 在 `stop` 之前插入 `<i>Don't</i>`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<b><i>Don't</i> ever stop</b>"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.b.i.insert_after(soup.new_string(\" ever \"))\n",
    "soup.b\n",
    "# 在 `</i>` 后面插入 ` ever `"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<i>Don't</i>, ' ever ', 'stop']"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.b.contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## clear()\n",
    "\n",
    "Tag.clear() 方法移除当前tag的内容:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<a href=\"http://example.com/\">I linked to <i>example.com</i></a>"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "markup = '<a href=\"http://example.com/\">I linked to <i>example.com</i></a>'\n",
    "soup = BeautifulSoup(markup)\n",
    "tag = soup.a\n",
    "tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<a href=\"http://example.com/\"></a>"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag.clear()\n",
    "tag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## extract()\n",
    "\n",
    "PageElement.extract() 方法将当前tag移除文档树,并作为方法结果返回:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<a href=\"http://example.com/\">I linked to <i>example.com</i></a>"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "markup = '<a href=\"http://example.com/\">I linked to <i>example.com</i></a>'\n",
    "soup = BeautifulSoup(markup)\n",
    "a_tag = soup.a\n",
    "a_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<i>example.com</i>"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i_tag = soup.i.extract()\n",
    "i_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<a href=\"http://example.com/\">I linked to </a>"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<i>example.com</i>"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_tag.parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'example.com'"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 这个方法实际上产生了2个文档树: 一个是用来解析原始文档的 BeautifulSoup 对象,另一个是被移除并且返回的tag.被移除并返回的tag可以继续调用 extract 方法:\n",
    "my_string = i_tag.string.extract()\n",
    "my_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(my_string.parent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## decompose()\n",
    "\n",
    "Tag.decompose() 方法将当前节点移除文档树并完全销毁:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<a href=\"http://example.com/\">I linked to <i>example.com</i></a>"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "markup = '<a href=\"http://example.com/\">I linked to <i>example.com</i></a>'\n",
    "soup = BeautifulSoup(markup)\n",
    "a_tag = soup.a\n",
    "a_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<i>example.com</i>"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<a href=\"http://example.com/\">I linked to </a>"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.i.decompose()\n",
    "a_tag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## replace_with()\n",
    "\n",
    "PageElement.replace_with() 方法移除文档树中的某段内容,并用新tag或文本节点替代它:\n",
    "\n",
    "replace_with() 方法返回被替代的tag或文本节点,可以用来浏览或添加到文档树其它地方"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<a href=\"http://example.com/\">I linked to <i>example.com</i></a>"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "markup = '<a href=\"http://example.com/\">I linked to <i>example.com</i></a>'\n",
    "soup = BeautifulSoup(markup)\n",
    "a_tag = soup.a\n",
    "a_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<i>example.com</i>"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_tag.i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<a href=\"http://example.com/\">I linked to <b>example.net</b></a>"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用 <b> 代替 <i>\n",
    "new_tag = soup.new_tag(\"b\")\n",
    "new_tag.string = \"example.net\"\n",
    "a_tag.i.replace_with(new_tag)\n",
    "a_tag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## wrap()\n",
    "\n",
    "PageElement.wrap() 方法可以对指定的tag元素进行包装,并返回包装后的结果:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<b>I wish I was bold.</b>"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup = BeautifulSoup(\"<p>I wish I was bold.</p>\")\n",
    "soup.p.string.wrap(soup.new_tag(\"b\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<div><p><b>I wish I was bold.</b></p></div>"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.p.wrap(soup.new_tag(\"div\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## unwrap()\n",
    "\n",
    "Tag.unwrap() 方法与 wrap() 方法相反.将移除tag内的所有tag标签,该方法常被用来进行标记的解包:\n",
    "\n",
    "与 replace_with() 方法相同, unwrap() 方法返回被移除的tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<a href=\"http://example.com/\">I linked to <i>example.com</i></a>"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "markup = '<a href=\"http://example.com/\">I linked to <i>example.com</i></a>'\n",
    "soup = BeautifulSoup(markup)\n",
    "a_tag = soup.a\n",
    "a_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<a href=\"http://example.com/\">I linked to example.com</a>"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_tag.i.unwrap()\n",
    "a_tag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 输出"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 格式化输出\n",
    "\n",
    "prettify() 方法将Beautiful Soup的文档树格式化后以Unicode编码输出,每个XML/HTML标签都独占一行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<html>\\n <body>\\n  <a href=\"http://example.com/\">\\n   I linked to\\n   <i>\\n    example.com\\n   </i>\\n  </a>\\n </body>\\n</html>\\n'"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "markup = '<a href=\"http://example.com/\">I linked to <i>example.com</i></a>'\n",
    "soup = BeautifulSoup(markup)\n",
    "soup.prettify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html>\n",
      " <body>\n",
      "  <a href=\"http://example.com/\">\n",
      "   I linked to\n",
      "   <i>\n",
      "    example.com\n",
      "   </i>\n",
      "  </a>\n",
      " </body>\n",
      "</html>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<a href=\"http://example.com/\">\n",
      " I linked to\n",
      " <i>\n",
      "  example.com\n",
      " </i>\n",
      "</a>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# BeautifulSoup 对象和它的tag节点都可以调用 prettify() 方法:\n",
    "print(soup.a.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 压缩输出\n",
    "\n",
    "如果只想得到结果字符串,不重视格式,那么可以对一个 BeautifulSoup 对象或 Tag 对象使用Python的 unicode() 或 str() 方法:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<html><body><a href=\"http://example.com/\">I linked to <i>example.com</i></a></body></html>'"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(soup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 输出格式\n",
    "\n",
    "Beautiful Soup输出是会将HTML中的特殊字符转换成Unicode,比如“&lquot;”:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<html>\\n <body>\\n  <p>\\n   “Dammit!” he said.\\n  </p>\\n </body>\\n</html>\\n'"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup = BeautifulSoup(\"&ldquo;Dammit!&rdquo; he said.\")\n",
    "soup.decode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'<html><body><p>\\xe2\\x80\\x9cDammit!\\xe2\\x80\\x9d he said.</p></body></html>'"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.encode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<html><body><p>“Dammit!” he said.</p></body></html>'"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 如果将文档转换成字符串,Unicode编码会被编码成UTF-8.这样就无法正确显示HTML特殊字符了:\n",
    "str(soup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get_text()\n",
    "\n",
    "如果只想得到tag中包含的文本内容,那么可以用 get_text() 方法,这个方法获取到tag中包含的所有文版内容包括子孙tag中的内容,并将结果作为Unicode字符串返回:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nI linked to example.com\\n'"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "markup = '<a href=\"http://example.com/\">\\nI linked to <i>example.com</i>\\n</a>'\n",
    "soup = BeautifulSoup(markup)\n",
    "soup.get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'example.com'"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.i.get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nI linked to |example.com|\\n'"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 可以通过参数指定tag的文本内容的分隔符:\n",
    "soup.get_text(\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I linked to|example.com'"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 还可以去除获得文本内容的前后空白:\n",
    "soup.get_text(\"|\", strip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I linked to', 'example.com']"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 或者使用 .stripped_strings 生成器,获得文本列表后手动处理列表:\n",
    "[text for text in soup.stripped_strings]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 指定文档解析器\n",
    "\n",
    "如果仅是想要解析HTML文档,只要用文档创建 BeautifulSoup 对象就可以了.Beautiful Soup会自动选择一个解析器来解析文档.但是还可以通过参数指定使用那种解析器来解析当前文档.\n",
    "\n",
    "BeautifulSoup 第一个参数应该是要被解析的文档字符串或是文件句柄,第二个参数用来标识怎样解析文档.如果第二个参数为空,那么Beautiful Soup根据当前系统安装的库自动选择解析器,解析器的优先数序: lxml, html5lib, Python标准库.在下面两种条件下解析器优先顺序会变化:\n",
    "- 要解析的文档是什么类型: 目前支持, “html”, “xml”, 和 “html5”\n",
    "- 指定使用哪种解析器: 目前支持, “lxml”, “html5lib”, 和 “html.parser”\n",
    "\n",
    "安装解析器 章节介绍了可以使用哪种解析器,以及如何安装.\n",
    "\n",
    "如果指定的解析器没有安装,Beautiful Soup会自动选择其它方案.目前只有 lxml 解析器支持XML文档的解析,在没有安装lxml库的情况下,创建 beautifulsoup 对象时无论是否指定使用lxml,都无法得到解析后的对象"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 解析器之间的区别\n",
    "\n",
    "Beautiful Soup为不同的解析器提供了相同的接口,但解析器本身时有区别的.同一篇文档被不同的解析器解析后可能会生成不同结构的树型文档.区别最大的是HTML解析器和XML解析器,看下面片段被解析成HTML结构:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<html><body><a><b></b></a></body></html>"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BeautifulSoup(\"<a><b /></a>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n",
       "<a><b/></a>"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 因为空标签<b />不符合HTML标准,所以解析器把它解析成<b></b>\n",
    "# 同样的文档使用XML解析如下(解析XML需要安装lxml库).注意,空标签<b />依然被保留,并且文档前添加了XML头,而不是被包含在<html>标签内:\n",
    "BeautifulSoup(\"<a><b /></a>\", \"xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<html><body><a></a></body></html>"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# HTML解析器之间也有区别,如果被解析的HTML文档是标准格式,那么解析器之间没有任何差别,只是解析速度不同,结果都会返回正确的文档树.\n",
    "# 但是如果被解析文档不是标准格式,那么不同的解析器返回结果可能不同.下面例子中,使用lxml解析错误格式的文档,结果</p>标签被直接忽略掉了:\n",
    "BeautifulSoup(\"<a></p>\", \"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "ename": "FeatureNotFound",
     "evalue": "Couldn't find a tree builder with the features you requested: html5lib. Do you need to install a parser library?",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFeatureNotFound\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Administrator\\Desktop\\self\\PythonLearn\\01\\BeautifulSoup\\bs4.ipynb 单元格 323\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Administrator/Desktop/self/PythonLearn/01/BeautifulSoup/bs4.ipynb#Y640sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# 使用html5lib库解析相同文档会得到不同的结果:\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Administrator/Desktop/self/PythonLearn/01/BeautifulSoup/bs4.ipynb#Y640sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m BeautifulSoup(\u001b[39m\"\u001b[39;49m\u001b[39m<a></p>\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mhtml5lib\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[1;32md:\\miniconda3\\envs\\pytorch\\Lib\\site-packages\\bs4\\__init__.py:250\u001b[0m, in \u001b[0;36mBeautifulSoup.__init__\u001b[1;34m(self, markup, features, builder, parse_only, from_encoding, exclude_encodings, element_classes, **kwargs)\u001b[0m\n\u001b[0;32m    248\u001b[0m     builder_class \u001b[39m=\u001b[39m builder_registry\u001b[39m.\u001b[39mlookup(\u001b[39m*\u001b[39mfeatures)\n\u001b[0;32m    249\u001b[0m     \u001b[39mif\u001b[39;00m builder_class \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 250\u001b[0m         \u001b[39mraise\u001b[39;00m FeatureNotFound(\n\u001b[0;32m    251\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mCouldn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt find a tree builder with the features you \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    252\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mrequested: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m. Do you need to install a parser library?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    253\u001b[0m             \u001b[39m%\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(features))\n\u001b[0;32m    255\u001b[0m \u001b[39m# At this point either we have a TreeBuilder instance in\u001b[39;00m\n\u001b[0;32m    256\u001b[0m \u001b[39m# builder, or we have a builder_class that we can instantiate\u001b[39;00m\n\u001b[0;32m    257\u001b[0m \u001b[39m# with the remaining **kwargs.\u001b[39;00m\n\u001b[0;32m    258\u001b[0m \u001b[39mif\u001b[39;00m builder \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mFeatureNotFound\u001b[0m: Couldn't find a tree builder with the features you requested: html5lib. Do you need to install a parser library?"
     ]
    }
   ],
   "source": [
    "# 使用html5lib库解析相同文档会得到不同的结果:\n",
    "BeautifulSoup(\"<a></p>\", \"html5lib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<a></a>"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# html5lib库没有忽略掉</p>标签,而是自动补全了标签,还给文档树添加了<head>标签.\n",
    "# 使用pyhton内置库解析结果如下:\n",
    "BeautifulSoup(\"<a></p>\", \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 与lxml库类似的,Python内置库忽略掉了</p>标签,与html5lib库不同的是标准库没有尝试创建符合标准的文档格式或将文档片段包含在<body>标签内,与lxml不同的是标准库甚至连<html>标签都没有尝试去添加.\n",
    "# 因为文档片段“<a></p>”是错误格式,所以以上解析方式都能算作”正确”,html5lib库使用的是HTML5的部分标准,所以最接近”正确”.不过所有解析器的结构都能够被认为是”正常”的.\n",
    "# 不同的解析器可能影响代码执行结果,如果在分发给别人的代码中使用了 BeautifulSoup ,那么最好注明使用了哪种解析器,以减少不必要的麻烦."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 编码\n",
    "\n",
    "任何HTML或XML文档都有自己的编码方式,比如ASCII 或 UTF-8,但是使用Beautiful Soup解析后,文档都被转换成了Unicode:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<html><body><h1>SacrÃ© bleu!</h1></body></html>"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "markup = \"<h1>Sacr\\xc3\\xa9 bleu!</h1>\"\n",
    "soup = BeautifulSoup(markup)\n",
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<h1>SacrÃ© bleu!</h1>"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.h1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SacrÃ© bleu!'"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.h1.string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 这不是魔术(但很神奇),Beautiful Soup用了编码自动检测 子库来识别当前文档编码并转换成Unicode编码. BeautifulSoup 对象的 .original_encoding 属性记录了自动识别编码的结果:\n",
    "soup.original_encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 编码自动检测 功能大部分时候都能猜对编码格式,但有时候也会出错.有时候即使猜测正确,也是在逐个字节的遍历整个文档后才猜对的,这样很慢.如果预先知道文档编码,可以设置编码参数来减少自动检查编码出错的概率并且提高文档解析速度.在创建 BeautifulSoup 对象的时候设置 from_encoding 参数."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<html><body><h1>翴檛</h1></body></html>"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 下面一段文档用了ISO-8859-8编码方式,这段文档太短,结果Beautiful Soup以为文档是用ISO-8859-7编码:\n",
    "markup = b\"<h1>\\xed\\xe5\\xec\\xf9</h1>\"\n",
    "soup = BeautifulSoup(markup)\n",
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<h1>翴檛</h1>"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.h1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Big5'"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.original_encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<h1>םולש</h1>"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 通过传入 from_encoding 参数来指定编码方式:\n",
    "soup = BeautifulSoup(markup, from_encoding=\"iso-8859-8\")\n",
    "soup.h1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'iso-8859-8'"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.original_encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 少数情况下(通常是UTF-8编码的文档中包含了其它编码格式的文件),想获得正确的Unicode编码就不得不将文档中少数特殊编码字符替换成特殊Unicode编码,“REPLACEMENT CHARACTER” (U+FFFD, �) [9] . 如果Beautifu Soup猜测文档编码时作了特殊字符的替换,那么Beautiful Soup会把 UnicodeDammit 或 BeautifulSoup 对象的 .contains_replacement_characters 属性标记为 True .这样就可以知道当前文档进行Unicode编码后丢失了一部分特殊内容字符.如果文档中包含�而 .contains_replacement_characters 属性是 False ,则表示�就是文档中原来的字符,不是转码失败."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 输出编码\n",
    "\n",
    "通过Beautiful Soup输出文档时,不管输入文档是什么编码方式,输出编码均为UTF-8编码,下面例子输入文档是Latin-1编码:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html>\n",
      " <head>\n",
      "  <meta content=\"text/html; charset=utf-8\" http-equiv=\"Content-type\"/>\n",
      " </head>\n",
      " <body>\n",
      "  <p>\n",
      "   Sacré bleu!\n",
      "  </p>\n",
      " </body>\n",
      "</html>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "markup = b'''\n",
    "<html>\n",
    "  <head>\n",
    "    <meta content=\"text/html; charset=ISO-Latin-1\" http-equiv=\"Content-type\" />\n",
    "  </head>\n",
    "  <body>\n",
    "    <p>Sacr\\xe9 bleu!</p>\n",
    "  </body>\n",
    "</html>\n",
    "'''\n",
    "soup = BeautifulSoup(markup)\n",
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'<html>\\n <head>\\n  <meta content=\"text/html; charset=latin-1\" http-equiv=\"Content-type\"/>\\n </head>\\n <body>\\n  <p>\\n   Sacr\\xe9 bleu!\\n  </p>\\n </body>\\n</html>\\n'\n"
     ]
    }
   ],
   "source": [
    "# 注意,输出文档中的<meta>标签的编码设置已经修改成了与输出编码一致的UTF-8.\n",
    "# 如果不想用UTF-8编码输出,可以将编码方式传入 prettify() 方法:\n",
    "print(soup.prettify(\"latin-1\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'<p>Sacr\\xe9 bleu!</p>'"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 还可以调用 BeautifulSoup 对象或任意节点的 encode() 方法,就像Python的字符串调用 encode() 方法一样:\n",
    "soup.p.encode(\"latin-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'<p>Sacr\\xc3\\xa9 bleu!</p>'"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.p.encode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<html><body><b>☃</b></body></html>"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 如果文档中包含当前编码不支持的字符,那么这些字符将呗转换成一系列XML特殊字符引用,下面例子中包含了Unicode编码字符SNOWMAN:\n",
    "markup = u\"<b>\\N{SNOWMAN}</b>\"\n",
    "snowman_soup = BeautifulSoup(markup)\n",
    "snowman_soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<b>☃</b>"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag = snowman_soup.b\n",
    "tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'<b>\\xe2\\x98\\x83</b>'\n"
     ]
    }
   ],
   "source": [
    "# SNOWMAN字符在UTF-8编码中可以正常显示(看上去像是☃),但有些编码不支持SNOWMAN字符,比如ISO-Latin-1或ASCII,那么在这些编码中SNOWMAN字符会被转换成“&#9731”:\n",
    "print(tag.encode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'<b>&#9731;</b>'\n"
     ]
    }
   ],
   "source": [
    "print(tag.encode(\"latin-1\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'<b>&#9731;</b>'\n"
     ]
    }
   ],
   "source": [
    "print(tag.encode(\"ascii\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unicode, dammit! (靠!)\n",
    "\n",
    "编码自动检测 功能可以在Beautiful Soup以外使用,检测某段未知编码时,可以使用这个方法:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SacrÃ© bleu!'"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import UnicodeDammit\n",
    "dammit = UnicodeDammit(\"Sacr\\xc3\\xa9 bleu!\")\n",
    "dammit.unicode_markup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "dammit.original_encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sacré bleu!\n"
     ]
    }
   ],
   "source": [
    "# 如果Python中安装了 chardet 或 cchardet 那么编码检测功能的准确率将大大提高.输入的字符越多,检测结果越精确,如果事先猜测到一些可能编码,那么可以将猜测的编码作为参数,这样将优先检测这些编码:\n",
    "dammit = UnicodeDammit(\"Sacr\\xe9 bleu!\", [\"latin-1\", \"iso-8859-1\"])\n",
    "print(dammit.unicode_markup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "dammit.original_encoding\n",
    "# 编码自动检测 功能中有2项功能是Beautiful Soup库中用不到的"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 智能引号\n",
    "\n",
    "使用Unicode时,Beautiful Soup还会智能的把引号 [10] 转换成HTML或XML中的特殊字符:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<p>I just &ldquo;love&rdquo; Microsoft Word&rsquo;s smart quotes</p>'"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "markup = b\"<p>I just \\x93love\\x94 Microsoft Word\\x92s smart quotes</p>\"\n",
    "UnicodeDammit(markup, [\"windows-1252\"], smart_quotes_to=\"html\").unicode_markup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<p>I just &#x201C;love&#x201D; Microsoft Word&#x2019;s smart quotes</p>'"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "UnicodeDammit(markup, [\"windows-1252\"], smart_quotes_to=\"xml\").unicode_markup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<p>I just \"love\" Microsoft Word\\'s smart quotes</p>'"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 也可以把引号转换为ASCII码:\n",
    "UnicodeDammit(markup, [\"windows-1252\"], smart_quotes_to=\"ascii\").unicode_markup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<p>I just “love” Microsoft Word’s smart quotes</p>'"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 很有用的功能,但是Beautiful Soup没有使用这种方式.默认情况下,Beautiful Soup把引号转换成Unicode:\n",
    "UnicodeDammit(markup, [\"windows-1252\"]).unicode_markup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 矛盾的编码\n",
    "\n",
    "有时文档的大部分都是用UTF-8,但同时还包含了Windows-1252编码的字符,就像微软的智能引号 [10] 一样.一些包含多个信息的来源网站容易出现这种情况. UnicodeDammit.detwingle() 方法可以把这类文档转换成纯UTF-8编码格式,看个简单的例子:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'\\xe2\\x98\\x83\\xe2\\x98\\x83\\xe2\\x98\\x83\\x93I like snowmen!\\x94'"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snowmen = (u\"\\N{SNOWMAN}\" * 3)\n",
    "quote = (u\"\\N{LEFT DOUBLE QUOTATION MARK}I like snowmen!\\N{RIGHT DOUBLE QUOTATION MARK}\")\n",
    "doc = snowmen.encode(\"utf8\") + quote.encode(\"windows_1252\")\n",
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'\\xe2\\x98\\x83\\xe2\\x98\\x83\\xe2\\x98\\x83\\x93I like snowmen!\\x94'\n"
     ]
    }
   ],
   "source": [
    "# 这段文档很杂乱,snowmen是UTF-8编码,引号是Windows-1252编码,直接输出时不能同时显示snowmen和引号,因为它们编码不同:\n",
    "print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â˜ƒâ˜ƒâ˜ƒ“I like snowmen!”\n"
     ]
    }
   ],
   "source": [
    "print(doc.decode(\"windows-1252\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "☃☃☃“I like snowmen!”\n"
     ]
    }
   ],
   "source": [
    "# 如果对这段文档用UTF-8解码就会得到 UnicodeDecodeError 异常,如果用Windows-1252解码就回得到一堆乱码.幸好, UnicodeDammit.detwingle() 方法会吧这段字符串转换成UTF-8编码,允许我们同时显示出文档中的snowmen和引号:\n",
    "new_doc = UnicodeDammit.detwingle(doc)\n",
    "print(new_doc.decode(\"utf8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UnicodeDammit.detwingle() 方法只能解码包含在UTF-8编码中的Windows-1252编码内容,但这解决了最常见的一类问题.\n",
    "# 在创建 BeautifulSoup 或 UnicodeDammit 对象前一定要先对文档调用 UnicodeDammit.detwingle() 确保文档的编码方式正确.如果尝试去解析一段包含Windows-1252编码的UTF-8文档,就会得到一堆乱码,比如: â˜ƒâ˜ƒâ˜ƒ“I like snowmen!”."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 解析部分文档\n",
    "\n",
    "如果仅仅因为想要查找文档中的\\<a>标签而将整片文档进行解析,实在是浪费内存和时间.最快的方法是从一开始就把\\<a>标签以外的东西都忽略掉. SoupStrainer 类可以定义文档的某段内容,这样搜索文档时就不必先解析整篇文档,只会解析在 SoupStrainer 中定义过的文档. 创建一个 SoupStrainer 对象并作为 parse_only 参数给 BeautifulSoup 的构造方法即可."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SoupStrainer\n",
    "\n",
    "SoupStrainer 类接受与典型搜索方法相同的参数：name , attrs , recursive , text , **kwargs 。下面举例说明三种 SoupStrainer 对象："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bs4.element.SoupStrainer at 0x22d4d1db4d0>"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import SoupStrainer\n",
    "only_a_tags = SoupStrainer(\"a\")\n",
    "only_a_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bs4.element.SoupStrainer at 0x22d4d165dd0>"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "only_tags_with_id_link2 = SoupStrainer(id=\"link2\")\n",
    "only_tags_with_id_link2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_19080\\2913288262.py:3: DeprecationWarning: The 'text' argument to the SoupStrainer constructor is deprecated. Use 'string' instead.\n",
      "  only_short_strings = SoupStrainer(text=is_short_string)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<bs4.element.SoupStrainer at 0x22d4d42c650>"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def is_short_string(string):\n",
    "    return len(string) < 10\n",
    "only_short_strings = SoupStrainer(text=is_short_string)\n",
    "only_short_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">\n",
      " Elsie\n",
      "</a>\n",
      "<a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">\n",
      " Lacie\n",
      "</a>\n",
      "<a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">\n",
      " Tillie\n",
      "</a>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 再拿“爱丽丝”文档来举例，来看看使用三种 SoupStrainer 对象做参数会有什么不同:\n",
    "html_doc = \"\"\"\n",
    "<html><head><title>The Dormouse's story</title></head>\n",
    "\n",
    "<p class=\"title\"><b>The Dormouse's story</b></p>\n",
    "\n",
    "<p class=\"story\">Once upon a time there were three little sisters; and their names were\n",
    "<a href=\"http://example.com/elsie\" class=\"sister\" id=\"link1\">Elsie</a>,\n",
    "<a href=\"http://example.com/lacie\" class=\"sister\" id=\"link2\">Lacie</a> and\n",
    "<a href=\"http://example.com/tillie\" class=\"sister\" id=\"link3\">Tillie</a>;\n",
    "and they lived at the bottom of a well.</p>\n",
    "\n",
    "<p class=\"story\">...</p>\n",
    "\"\"\"\n",
    "print(BeautifulSoup(html_doc, \"html.parser\", parse_only=only_a_tags).prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">\n",
      " Lacie\n",
      "</a>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(BeautifulSoup(html_doc, \"html.parser\", parse_only=only_tags_with_id_link2).prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elsie\n",
      ",\n",
      "Lacie\n",
      "and\n",
      "Tillie\n",
      "...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(BeautifulSoup(html_doc, \"html.parser\", parse_only=only_short_strings).prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n', '\\n', 'Elsie', ',\\n', 'Lacie', ' and\\n', 'Tillie', '\\n', '...', '\\n']"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 还可以将 SoupStrainer 作为参数传入 搜索文档树 中提到的方法.这可能不是个常用用法,所以还是提一下:\n",
    "soup = BeautifulSoup(html_doc)\n",
    "soup.find_all(only_short_strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
